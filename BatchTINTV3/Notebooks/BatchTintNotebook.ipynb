{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "notebook_path = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "# the code path is two folders up from this notebook + /code\n",
    "core_path = os.path.dirname(notebook_path)\n",
    "basepath = os.path.dirname(os.path.dirname(notebook_path))\n",
    "\n",
    "sys.path.append(core_path)\n",
    "sys.path.append(basepath)\n",
    "\n",
    "from core.klusta_functions import klusta\n",
    "from core.klusta_utils import session_analyzable, find_tetrodes\n",
    "from core.Tint_Matlab import get_setfile_parameter\n",
    "from core.defaultParameters import get_default_settings, calculateUseFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = get_default_settings()\n",
    "\n",
    "# the default naming structure is the directory\\session_basename_tetrodeNumber.cut\n",
    "# for example: C:\\Example\\ExampleSession_1.cut for tetrode 1.\n",
    "# However, there may be a cause where you want to re-analyze with different cut file nomenclature\n",
    "# so we will allow you to append a value to the end to produce the following:\n",
    "# directory\\session_basename[appendValue]_tetrodeNumber.cut\n",
    "# so if we append 'TEST' the output would be: C:\\Example\\ExampleSessionTEST_1.cut for tetrode 1\n",
    "# set the cut_append value to None for the default\n",
    "cut_append='KK'  # custom append value\n",
    "# cut_append=None  # uncomment this for default value\n",
    "\n",
    "# channels to use:\n",
    "settings['1'] = 1  # defaults to 1, which is on\n",
    "settings['2'] = 1  # defaults to 1, which is on\n",
    "settings['3'] = 1  # defaults to 1, which is on\n",
    "settings['4'] = 1  # defaults to 1, which is on\n",
    "\n",
    "# features to use:\n",
    "settings['PC1'] = 1  # defaults to 1, which is on\n",
    "settings['PC2'] = 1  # defaults to 1, which is on\n",
    "settings['PC3'] = 1  # defaults to 1, which is on\n",
    "settings['PC4'] = 0  # defaults to 0, which is off\n",
    "settings['A'] = 0  # defaults to 0, which is off\n",
    "settings['Vt'] = 0  # defaults to 0, which is off\n",
    "settings['P'] = 0  # defaults to 0, which is off\n",
    "settings['T'] = 0  # defaults to 0, which is off\n",
    "settings['tP'] = 0  # defaults to 0, which is off\n",
    "settings['tT'] = 0  # defaults to 0, which is off\n",
    "settings['En'] = 0  # defaults to 0, which is off\n",
    "settings['Ar'] = 0  # defaults to 0, which is off\n",
    "\n",
    "# re-caculating the feature masks (if channel 2 is off, we will make sure to ignore\n",
    "# those features)\n",
    "UseFeatures, numFeats = calculateUseFeatures(settings)\n",
    "settings['UseFeatures'] = UseFeatures  # feature mask\n",
    "settings['NumFeat'] = numFeats  # number of features used\n",
    "\n",
    "# Advanced KlustaKwik Parameters\n",
    "settings['MaxPos'] = 30  # default 3\n",
    "settings['nStarts'] = 1  # default = 1\n",
    "settings['RandomSeed'] = 1  # default = 1\n",
    "settings['DistThresh'] = 6.907755  # default is 6.907755\n",
    "settings['FullStepEvery'] = 20  # default is 20\n",
    "settings['ChangedThresh'] = 0.05  # default is 0.05\n",
    "settings['MaxIter'] = 500  # default is 500\n",
    "settings['SplitEvery'] = 40  # default is 40\n",
    "settings['Subset'] = 1 # default is 1\n",
    "settings['PenaltyK'] = 1.0  # default is 1.0\n",
    "settings['PenaltyKLogN'] = 0.0  # default is 0.0\n",
    "\n",
    "# Reporting Values\n",
    "settings['Verbose'] = 1  # default of 1\n",
    "settings['Screen'] = 1  # default of 1\n",
    "settings['Log File'] = 1  # default of 1\n",
    "\n",
    "\n",
    "# Misc Settings\n",
    "settings['Silent'] = 0   # the KK windows will pop up\n",
    "# number of simultaneous threads to analyze, defaults to 1, uncomment to override\n",
    "settings['NumThreads'] = 4  # default is 1\n",
    "settings['Cores'] = os.cpu_count()\n",
    "\n",
    "# Experimenter Settings\n",
    "experimenter_settings = {\n",
    "    'Geoff' : 'geoffrey.m.barrett@gmail.com' # can do [email1@.., email2@..] if you want it sent to more than 1\n",
    "}\n",
    "\n",
    "# Email Settings\n",
    "smtp_settings = {}\n",
    "smtp_settings['Notification'] = 0 #  1 for send e-mails, 0 for don't send\n",
    "\n",
    "# if you have the notifications set to 0 you don't have to worry about this.\n",
    "# we will need an e-mail to send these experimenter's e-mails from\n",
    "smtp_settings['Username'] = 'example@gmail.com'\n",
    "smtp_settings['Password'] = 'password'  # associated password\n",
    "smtp_settings['ServerName'] = 'smtp.gmail.com' # the smtp server name, 'smtp.gmail.com' for gmail\n",
    "smtp_settings['Port'] = 587  # 587 default for gmail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = False\n",
    "\n",
    "if batch:\n",
    "    settings['nonbatch'] = 0\n",
    "else:\n",
    "    settings['nonbatch'] = 1\n",
    "\n",
    "settings['MoveFiles'] = 0  # set to 1 if you want to move to \"processed\" folder\n",
    "    \n",
    "directory = r'E:\\Apollo_D_Drive\\data\\VirtualMazeData\\ANT1_2\\ParallelLinearGlobalTrack'\n",
    "# directory = r'C:\\Users\\Taub Institute\\Desktop\\test_batchtint'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finds Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "if batch:\n",
    "    sub_directories = [d for d in os.listdir(directory)\n",
    "                                   if os.path.isdir(os.path.join(directory, d)) and\n",
    "                                   d not in ['Processed', 'Converted']]  # finds the subdirectories within each folder\n",
    "\n",
    "else:\n",
    "    sub_directories = [os.path.basename(directory)]\n",
    "    directory = os.path.dirname(directory)\n",
    "\n",
    "set_files = []\n",
    "if len(sub_directories) > 0:\n",
    "    [[set_files.append(os.path.join(directory, d, file)) for file in os.listdir(os.path.join(directory, d))\n",
    "                             if '.set' in file and\n",
    "                             not os.path.isdir(os.path.join(directory, d, file))] for d in sub_directories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 17 total set files found!\n"
     ]
    }
   ],
   "source": [
    "print('There are %d total set files found!' % (len(set_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking that the set files are analyzable (have the appropriate files, or don't have\n",
    "# existing cut values already. Essentially all it needs are the tetrode files.\n",
    "if set_files:\n",
    "    set_files = [file for file in set_files if session_analyzable(os.path.dirname(file), \n",
    "                                                             os.path.splitext(\n",
    "                                                                 os.path.basename(file))[0],\n",
    "                                                            append=cut_append)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10 un-analyzed set files found!\n"
     ]
    }
   ],
   "source": [
    "print('There are %d un-analyzed set files found!' % (len(set_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-04-03 14:15:28]: There are 10 '.set' files to analyze!\n",
      "[2019-04-03 14:15:28]: Now analyzing tetrodes associated with the ANT_1_2_1075_plgt_190314_145652_ms '.set' file (1/10)!\n",
      "[2019-04-03 14:15:28]: Now analyzing the following file: ANT_1_2_1075_plgt_190314_145652_ms.1!\n",
      "[2019-04-03 14:15:28]: Now analyzing the following file: ANT_1_2_1075_plgt_190314_145652_ms.2!\n",
      "[2019-04-03 14:15:28]: Now analyzing the following file: ANT_1_2_1075_plgt_190314_145652_ms.3!\n",
      "[2019-04-03 14:15:28]: Now analyzing the following file: ANT_1_2_1075_plgt_190314_145652_ms.4!\n",
      "[2019-04-03 14:16:58]: The analysis of the ANT_1_2_1075_plgt_190314_145652_ms.3 file has finished!\n",
      "[2019-04-03 14:17:53]: The analysis of the ANT_1_2_1075_plgt_190314_145652_ms.2 file has finished!\n",
      "[2019-04-03 14:18:23]: The analysis of the ANT_1_2_1075_plgt_190314_145652_ms.1 file has finished!\n",
      "[2019-04-03 14:19:13]: The analysis of the ANT_1_2_1075_plgt_190314_145652_ms.4 file has finished!\n",
      "[2019-04-03 14:19:13]: Now analyzing the following file: ANT_1_2_1075_plgt_190314_145652_ms.5!\n",
      "[2019-04-03 14:19:13]: Now analyzing the following file: ANT_1_2_1075_plgt_190314_145652_ms.6!\n",
      "[2019-04-03 14:19:13]: Now analyzing the following file: ANT_1_2_1075_plgt_190314_145652_ms.7!\n",
      "[2019-04-03 14:19:13]: Now analyzing the following file: ANT_1_2_1075_plgt_190314_145652_ms.8!\n",
      "[2019-04-03 14:20:22]: The analysis of the ANT_1_2_1075_plgt_190314_145652_ms.8 file has finished!\n",
      "[2019-04-03 14:20:54]: The analysis of the ANT_1_2_1075_plgt_190314_145652_ms.6 file has finished!\n",
      "[2019-04-03 14:20:56]: The analysis of the ANT_1_2_1075_plgt_190314_145652_ms.5 file has finished!\n",
      "[2019-04-03 14:21:32]: The analysis of the ANT_1_2_1075_plgt_190314_145652_ms.7 file has finished!\n",
      "[2019-04-03 14:21:32]: Now analyzing tetrodes associated with the ANT_1_2_1100_plgt_190315_144842_ms '.set' file (2/10)!\n",
      "[2019-04-03 14:21:32]: Now analyzing the following file: ANT_1_2_1100_plgt_190315_144842_ms.1!\n",
      "[2019-04-03 14:21:32]: Now analyzing the following file: ANT_1_2_1100_plgt_190315_144842_ms.2!\n",
      "[2019-04-03 14:21:32]: Now analyzing the following file: ANT_1_2_1100_plgt_190315_144842_ms.3!\n",
      "[2019-04-03 14:21:32]: Now analyzing the following file: ANT_1_2_1100_plgt_190315_144842_ms.4!\n",
      "[2019-04-03 14:23:02]: The analysis of the ANT_1_2_1100_plgt_190315_144842_ms.3 file has finished!\n",
      "[2019-04-03 14:26:46]: The analysis of the ANT_1_2_1100_plgt_190315_144842_ms.2 file has finished!\n",
      "[2019-04-03 14:28:40]: The analysis of the ANT_1_2_1100_plgt_190315_144842_ms.4 file has finished!\n",
      "[2019-04-03 14:28:52]: The analysis of the ANT_1_2_1100_plgt_190315_144842_ms.1 file has finished!\n",
      "[2019-04-03 14:28:52]: Now analyzing the following file: ANT_1_2_1100_plgt_190315_144842_ms.5!\n",
      "[2019-04-03 14:28:52]: Now analyzing the following file: ANT_1_2_1100_plgt_190315_144842_ms.6!\n",
      "[2019-04-03 14:28:52]: Now analyzing the following file: ANT_1_2_1100_plgt_190315_144842_ms.7!\n",
      "[2019-04-03 14:28:52]: Now analyzing the following file: ANT_1_2_1100_plgt_190315_144842_ms.8!\n",
      "[2019-04-03 14:32:07]: The analysis of the ANT_1_2_1100_plgt_190315_144842_ms.8 file has finished!\n",
      "[2019-04-03 14:33:36]: The analysis of the ANT_1_2_1100_plgt_190315_144842_ms.6 file has finished!\n",
      "[2019-04-03 14:33:44]: The analysis of the ANT_1_2_1100_plgt_190315_144842_ms.7 file has finished!\n",
      "[2019-04-03 14:33:48]: The analysis of the ANT_1_2_1100_plgt_190315_144842_ms.5 file has finished!\n",
      "[2019-04-03 14:33:48]: Now analyzing tetrodes associated with the ant_1_2_1175_plgt_190319_144335_ms '.set' file (3/10)!\n",
      "[2019-04-03 14:33:48]: Now analyzing the following file: ant_1_2_1175_plgt_190319_144335_ms.1!\n",
      "[2019-04-03 14:33:48]: Now analyzing the following file: ant_1_2_1175_plgt_190319_144335_ms.2!\n",
      "[2019-04-03 14:33:48]: Now analyzing the following file: ant_1_2_1175_plgt_190319_144335_ms.3!\n",
      "[2019-04-03 14:33:48]: Now analyzing the following file: ant_1_2_1175_plgt_190319_144335_ms.4!\n",
      "[2019-04-03 14:34:46]: The analysis of the ant_1_2_1175_plgt_190319_144335_ms.3 file has finished!\n",
      "[2019-04-03 14:34:56]: The analysis of the ant_1_2_1175_plgt_190319_144335_ms.2 file has finished!\n",
      "[2019-04-03 14:35:04]: The analysis of the ant_1_2_1175_plgt_190319_144335_ms.4 file has finished!\n",
      "[2019-04-03 14:36:16]: The analysis of the ant_1_2_1175_plgt_190319_144335_ms.1 file has finished!\n",
      "[2019-04-03 14:36:16]: Now analyzing the following file: ant_1_2_1175_plgt_190319_144335_ms.5!\n",
      "[2019-04-03 14:36:16]: Now analyzing the following file: ant_1_2_1175_plgt_190319_144335_ms.6!\n",
      "[2019-04-03 14:36:16]: Now analyzing the following file: ant_1_2_1175_plgt_190319_144335_ms.7!\n",
      "[2019-04-03 14:36:16]: Now analyzing the following file: ant_1_2_1175_plgt_190319_144335_ms.8!\n",
      "[2019-04-03 14:37:05]: The analysis of the ant_1_2_1175_plgt_190319_144335_ms.5 file has finished!\n",
      "[2019-04-03 14:37:27]: The analysis of the ant_1_2_1175_plgt_190319_144335_ms.6 file has finished!\n",
      "[2019-04-03 14:37:27]: The analysis of the ant_1_2_1175_plgt_190319_144335_ms.8 file has finished!\n",
      "[2019-04-03 14:37:33]: The analysis of the ant_1_2_1175_plgt_190319_144335_ms.7 file has finished!\n",
      "[2019-04-03 14:37:33]: Now analyzing tetrodes associated with the ant_1_2_1175_plgt_190320_143032_ms '.set' file (4/10)!\n",
      "[2019-04-03 14:37:33]: Now analyzing the following file: ant_1_2_1175_plgt_190320_143032_ms.1!\n",
      "[2019-04-03 14:37:33]: Now analyzing the following file: ant_1_2_1175_plgt_190320_143032_ms.2!\n",
      "[2019-04-03 14:37:33]: Now analyzing the following file: ant_1_2_1175_plgt_190320_143032_ms.3!\n",
      "[2019-04-03 14:37:33]: Now analyzing the following file: ant_1_2_1175_plgt_190320_143032_ms.4!\n",
      "[2019-04-03 14:38:37]: The analysis of the ant_1_2_1175_plgt_190320_143032_ms.2 file has finished!\n",
      "[2019-04-03 14:38:37]: The analysis of the ant_1_2_1175_plgt_190320_143032_ms.3 file has finished!\n",
      "[2019-04-03 14:38:41]: The analysis of the ant_1_2_1175_plgt_190320_143032_ms.4 file has finished!\n",
      "[2019-04-03 14:39:47]: The analysis of the ant_1_2_1175_plgt_190320_143032_ms.1 file has finished!\n",
      "[2019-04-03 14:39:47]: Now analyzing the following file: ant_1_2_1175_plgt_190320_143032_ms.5!\n",
      "[2019-04-03 14:39:47]: Now analyzing the following file: ant_1_2_1175_plgt_190320_143032_ms.6!\n",
      "[2019-04-03 14:39:47]: Now analyzing the following file: ant_1_2_1175_plgt_190320_143032_ms.7!\n",
      "[2019-04-03 14:39:47]: Now analyzing the following file: ant_1_2_1175_plgt_190320_143032_ms.8!\n",
      "[2019-04-03 14:40:39]: The analysis of the ant_1_2_1175_plgt_190320_143032_ms.5 file has finished!\n",
      "[2019-04-03 14:40:46]: The analysis of the ant_1_2_1175_plgt_190320_143032_ms.8 file has finished!\n",
      "[2019-04-03 14:40:48]: The analysis of the ant_1_2_1175_plgt_190320_143032_ms.6 file has finished!\n",
      "[2019-04-03 14:40:54]: The analysis of the ant_1_2_1175_plgt_190320_143032_ms.7 file has finished!\n",
      "[2019-04-03 14:40:54]: Now analyzing tetrodes associated with the ant_1_2_1175_plgt_190321_125429_ms '.set' file (5/10)!\n",
      "[2019-04-03 14:40:54]: Now analyzing the following file: ant_1_2_1175_plgt_190321_125429_ms.1!\n",
      "[2019-04-03 14:40:54]: Now analyzing the following file: ant_1_2_1175_plgt_190321_125429_ms.2!\n",
      "[2019-04-03 14:40:54]: Now analyzing the following file: ant_1_2_1175_plgt_190321_125429_ms.3![2019-04-03 14:40:54]: Now analyzing the following file: ant_1_2_1175_plgt_190321_125429_ms.4!\n",
      "\n",
      "[2019-04-03 14:42:00]: The analysis of the ant_1_2_1175_plgt_190321_125429_ms.4 file has finished!\n",
      "[2019-04-03 14:42:36]: The analysis of the ant_1_2_1175_plgt_190321_125429_ms.2 file has finished!\n",
      "[2019-04-03 14:42:38]: The analysis of the ant_1_2_1175_plgt_190321_125429_ms.3 file has finished!\n",
      "[2019-04-03 14:43:14]: The analysis of the ant_1_2_1175_plgt_190321_125429_ms.1 file has finished!\n",
      "[2019-04-03 14:43:14]: Now analyzing the following file: ant_1_2_1175_plgt_190321_125429_ms.5!\n",
      "[2019-04-03 14:43:14]: Now analyzing the following file: ant_1_2_1175_plgt_190321_125429_ms.6!\n",
      "[2019-04-03 14:43:14]: Now analyzing the following file: ant_1_2_1175_plgt_190321_125429_ms.7!\n",
      "[2019-04-03 14:43:14]: Now analyzing the following file: ant_1_2_1175_plgt_190321_125429_ms.8!\n",
      "[2019-04-03 14:44:25]: The analysis of the ant_1_2_1175_plgt_190321_125429_ms.5 file has finished!\n",
      "[2019-04-03 14:44:25]: The analysis of the ant_1_2_1175_plgt_190321_125429_ms.8 file has finished!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-04-03 14:44:57]: The analysis of the ant_1_2_1175_plgt_190321_125429_ms.7 file has finished!\n",
      "[2019-04-03 14:45:07]: The analysis of the ant_1_2_1175_plgt_190321_125429_ms.6 file has finished!\n",
      "[2019-04-03 14:45:07]: Now analyzing tetrodes associated with the ant_1_2_1175_plgt_190321_141722_ms '.set' file (6/10)!\n",
      "[2019-04-03 14:45:07]: Now analyzing the following file: ant_1_2_1175_plgt_190321_141722_ms.1!\n",
      "[2019-04-03 14:45:07]: Now analyzing the following file: ant_1_2_1175_plgt_190321_141722_ms.2!\n",
      "[2019-04-03 14:45:07]: Now analyzing the following file: ant_1_2_1175_plgt_190321_141722_ms.3!\n",
      "[2019-04-03 14:45:07]: Now analyzing the following file: ant_1_2_1175_plgt_190321_141722_ms.4!\n",
      "[2019-04-03 14:46:15]: The analysis of the ant_1_2_1175_plgt_190321_141722_ms.4 file has finished!\n",
      "[2019-04-03 14:46:41]: The analysis of the ant_1_2_1175_plgt_190321_141722_ms.2 file has finished!\n",
      "[2019-04-03 14:47:58]: The analysis of the ant_1_2_1175_plgt_190321_141722_ms.3 file has finished!\n",
      "[2019-04-03 14:48:28]: The analysis of the ant_1_2_1175_plgt_190321_141722_ms.1 file has finished!\n",
      "[2019-04-03 14:48:28]: Now analyzing the following file: ant_1_2_1175_plgt_190321_141722_ms.5!\n",
      "[2019-04-03 14:48:28]: Now analyzing the following file: ant_1_2_1175_plgt_190321_141722_ms.6!\n",
      "[2019-04-03 14:48:28]: Now analyzing the following file: ant_1_2_1175_plgt_190321_141722_ms.7!\n",
      "[2019-04-03 14:48:28]: Now analyzing the following file: ant_1_2_1175_plgt_190321_141722_ms.8!\n",
      "[2019-04-03 14:49:34]: The analysis of the ant_1_2_1175_plgt_190321_141722_ms.5 file has finished!\n",
      "[2019-04-03 14:49:46]: The analysis of the ant_1_2_1175_plgt_190321_141722_ms.6 file has finished!\n",
      "[2019-04-03 14:49:58]: The analysis of the ant_1_2_1175_plgt_190321_141722_ms.8 file has finished!\n",
      "[2019-04-03 14:49:58]: The analysis of the ant_1_2_1175_plgt_190321_141722_ms.7 file has finished!\n",
      "[2019-04-03 14:49:58]: Now analyzing tetrodes associated with the ant_1_2_1175_plgt_190322_142539_ms '.set' file (7/10)!\n",
      "[2019-04-03 14:49:58]: Now analyzing the following file: ant_1_2_1175_plgt_190322_142539_ms.1!\n",
      "[2019-04-03 14:49:58]: Now analyzing the following file: ant_1_2_1175_plgt_190322_142539_ms.2!\n",
      "[2019-04-03 14:49:58]: Now analyzing the following file: ant_1_2_1175_plgt_190322_142539_ms.3!\n",
      "[2019-04-03 14:49:58]: Now analyzing the following file: ant_1_2_1175_plgt_190322_142539_ms.4!\n",
      "[2019-04-03 14:51:19]: The analysis of the ant_1_2_1175_plgt_190322_142539_ms.2 file has finished!\n",
      "[2019-04-03 14:51:25]: The analysis of the ant_1_2_1175_plgt_190322_142539_ms.3 file has finished!\n",
      "[2019-04-03 14:51:47]: The analysis of the ant_1_2_1175_plgt_190322_142539_ms.4 file has finished!\n",
      "[2019-04-03 14:52:09]: The analysis of the ant_1_2_1175_plgt_190322_142539_ms.1 file has finished!\n",
      "[2019-04-03 14:52:09]: Now analyzing the following file: ant_1_2_1175_plgt_190322_142539_ms.5!\n",
      "[2019-04-03 14:52:09]: Now analyzing the following file: ant_1_2_1175_plgt_190322_142539_ms.6!\n",
      "[2019-04-03 14:52:09]: Now analyzing the following file: ant_1_2_1175_plgt_190322_142539_ms.7!\n",
      "[2019-04-03 14:52:09]: Now analyzing the following file: ant_1_2_1175_plgt_190322_142539_ms.8!\n",
      "[2019-04-03 14:53:51]: The analysis of the ant_1_2_1175_plgt_190322_142539_ms.8 file has finished!\n",
      "[2019-04-03 14:54:11]: The analysis of the ant_1_2_1175_plgt_190322_142539_ms.7 file has finished!\n",
      "[2019-04-03 14:54:21]: The analysis of the ant_1_2_1175_plgt_190322_142539_ms.5 file has finished!\n",
      "[2019-04-03 14:55:10]: The analysis of the ant_1_2_1175_plgt_190322_142539_ms.6 file has finished!\n",
      "[2019-04-03 14:55:10]: Now analyzing tetrodes associated with the ant_1_2_1175_plgt_190322_153028_ms '.set' file (8/10)!\n",
      "[2019-04-03 14:55:10]: Now analyzing the following file: ant_1_2_1175_plgt_190322_153028_ms.1!\n",
      "[2019-04-03 14:55:10]: Now analyzing the following file: ant_1_2_1175_plgt_190322_153028_ms.2!\n",
      "[2019-04-03 14:55:10]: Now analyzing the following file: ant_1_2_1175_plgt_190322_153028_ms.3!\n",
      "[2019-04-03 14:55:10]: Now analyzing the following file: ant_1_2_1175_plgt_190322_153028_ms.4!\n",
      "[2019-04-03 14:56:10]: The analysis of the ant_1_2_1175_plgt_190322_153028_ms.2 file has finished!\n",
      "[2019-04-03 14:56:50]: The analysis of the ant_1_2_1175_plgt_190322_153028_ms.4 file has finished!\n",
      "[2019-04-03 14:57:30]: The analysis of the ant_1_2_1175_plgt_190322_153028_ms.1 file has finished!\n",
      "[2019-04-03 14:57:34]: The analysis of the ant_1_2_1175_plgt_190322_153028_ms.3 file has finished!\n",
      "[2019-04-03 14:57:34]: Now analyzing the following file: ant_1_2_1175_plgt_190322_153028_ms.5!\n",
      "[2019-04-03 14:57:34]: Now analyzing the following file: ant_1_2_1175_plgt_190322_153028_ms.6!\n",
      "[2019-04-03 14:57:34]: Now analyzing the following file: ant_1_2_1175_plgt_190322_153028_ms.7!\n",
      "[2019-04-03 14:57:34]: Now analyzing the following file: ant_1_2_1175_plgt_190322_153028_ms.8!\n",
      "[2019-04-03 14:59:17]: The analysis of the ant_1_2_1175_plgt_190322_153028_ms.6 file has finished!\n",
      "[2019-04-03 14:59:31]: The analysis of the ant_1_2_1175_plgt_190322_153028_ms.8 file has finished!\n",
      "[2019-04-03 14:59:41]: The analysis of the ant_1_2_1175_plgt_190322_153028_ms.7 file has finished!\n",
      "[2019-04-03 15:00:35]: The analysis of the ant_1_2_1175_plgt_190322_153028_ms.5 file has finished!\n",
      "[2019-04-03 15:00:35]: Now analyzing tetrodes associated with the ant_1_2_1175_plgt_190325_142826_ms '.set' file (9/10)!\n",
      "[2019-04-03 15:00:35]: Now analyzing the following file: ant_1_2_1175_plgt_190325_142826_ms.1!\n",
      "[2019-04-03 15:00:35]: Now analyzing the following file: ant_1_2_1175_plgt_190325_142826_ms.2!\n",
      "[2019-04-03 15:00:35]: Now analyzing the following file: ant_1_2_1175_plgt_190325_142826_ms.3!\n",
      "[2019-04-03 15:00:35]: Now analyzing the following file: ant_1_2_1175_plgt_190325_142826_ms.4!\n",
      "[2019-04-03 15:01:17]: The analysis of the ant_1_2_1175_plgt_190325_142826_ms.2 file has finished!\n",
      "[2019-04-03 15:02:26]: The analysis of the ant_1_2_1175_plgt_190325_142826_ms.3 file has finished!\n",
      "[2019-04-03 15:02:40]: The analysis of the ant_1_2_1175_plgt_190325_142826_ms.4 file has finished!\n",
      "[2019-04-03 15:02:44]: The analysis of the ant_1_2_1175_plgt_190325_142826_ms.1 file has finished!\n",
      "[2019-04-03 15:02:44]: Now analyzing the following file: ant_1_2_1175_plgt_190325_142826_ms.5!\n",
      "[2019-04-03 15:02:44]: Now analyzing the following file: ant_1_2_1175_plgt_190325_142826_ms.6!\n",
      "[2019-04-03 15:02:44]: Now analyzing the following file: ant_1_2_1175_plgt_190325_142826_ms.7!\n",
      "[2019-04-03 15:02:44]: Now analyzing the following file: ant_1_2_1175_plgt_190325_142826_ms.8!\n",
      "[2019-04-03 15:03:38]: The analysis of the ant_1_2_1175_plgt_190325_142826_ms.6 file has finished!\n",
      "[2019-04-03 15:05:11]: The analysis of the ant_1_2_1175_plgt_190325_142826_ms.5 file has finished!\n",
      "[2019-04-03 15:05:15]: The analysis of the ant_1_2_1175_plgt_190325_142826_ms.8 file has finished!\n",
      "[2019-04-03 15:06:07]: The analysis of the ant_1_2_1175_plgt_190325_142826_ms.7 file has finished!\n",
      "[2019-04-03 15:06:07]: Now analyzing tetrodes associated with the ant_1_2_1175_plgt_190325_151247_ms '.set' file (10/10)!\n",
      "[2019-04-03 15:06:07]: Now analyzing the following file: ant_1_2_1175_plgt_190325_151247_ms.1!\n",
      "[2019-04-03 15:06:07]: Now analyzing the following file: ant_1_2_1175_plgt_190325_151247_ms.2!\n",
      "[2019-04-03 15:06:07]: Now analyzing the following file: ant_1_2_1175_plgt_190325_151247_ms.3![2019-04-03 15:06:07]: Now analyzing the following file: ant_1_2_1175_plgt_190325_151247_ms.4!\n",
      "\n",
      "[2019-04-03 15:07:13]: The analysis of the ant_1_2_1175_plgt_190325_151247_ms.2 file has finished!\n",
      "[2019-04-03 15:08:08]: The analysis of the ant_1_2_1175_plgt_190325_151247_ms.3 file has finished!\n",
      "[2019-04-03 15:08:12]: The analysis of the ant_1_2_1175_plgt_190325_151247_ms.4 file has finished!\n",
      "[2019-04-03 15:08:40]: The analysis of the ant_1_2_1175_plgt_190325_151247_ms.1 file has finished!\n",
      "[2019-04-03 15:08:40]: Now analyzing the following file: ant_1_2_1175_plgt_190325_151247_ms.5!\n",
      "[2019-04-03 15:08:40]: Now analyzing the following file: ant_1_2_1175_plgt_190325_151247_ms.6!\n",
      "[2019-04-03 15:08:40]: Now analyzing the following file: ant_1_2_1175_plgt_190325_151247_ms.7!\n",
      "[2019-04-03 15:08:40]: Now analyzing the following file: ant_1_2_1175_plgt_190325_151247_ms.8!\n",
      "[2019-04-03 15:09:24]: The analysis of the ant_1_2_1175_plgt_190325_151247_ms.5 file has finished!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-04-03 15:09:34]: The analysis of the ant_1_2_1175_plgt_190325_151247_ms.6 file has finished!\n",
      "[2019-04-03 15:10:34]: The analysis of the ant_1_2_1175_plgt_190325_151247_ms.8 file has finished!\n",
      "[2019-04-03 15:11:10]: The analysis of the ant_1_2_1175_plgt_190325_151247_ms.7 file has finished!\n",
      "[2019-04-03 15:11:10]: Analysis for the following directory has been completed: E:\\Apollo_D_Drive\\data\\VirtualMazeData\\ANT1_2\\ParallelLinearGlobalTrack!\n"
     ]
    }
   ],
   "source": [
    "analyzed_set_files = klusta(set_files, settings, \n",
    "       smtp_settings=smtp_settings, \n",
    "       experimenter_settings=experimenter_settings,\n",
    "                           append=cut_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_temp_files(set_path, append=None):\n",
    "\n",
    "    append = cut_append\n",
    "    if append is None:\n",
    "        ini_filename_value = str('Filename=\"%s\"' % set_path)\n",
    "    else:\n",
    "        ini_filename_value = str('Filename=\"%s%s\"' % (set_path, append))\n",
    "\n",
    "    ini_filename_value = str('Filename=\"%s%s\"' % (set_path, append))\n",
    "\n",
    "    directory = os.path.dirname(set_path)\n",
    "    \n",
    "    basename = os.path.basename(set_path)\n",
    "    if append is not None:\n",
    "         basename += append\n",
    "    \n",
    "    file_list = os.listdir(directory)\n",
    "\n",
    "    temp_files = [os.path.join(directory, file) for file in file_list if basename in file and is_temp_ext(file)]\n",
    "    \n",
    "    return temp_files\n",
    "\n",
    "def ext_found(filename, ex):\n",
    "    if file.find(ex) != -1:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_temp_ext(filename):\n",
    "    \n",
    "    extensions = ['.temp.clu', '.klg', '.initialclusters.', '.fmask.', '.fet.']\n",
    "    \n",
    "    if any(ext_found(filename, ex) for ex in extensions):\n",
    "        for ex in extensions:\n",
    "            if ex in filename:\n",
    "                filename = filename[filename.find(ex):]\n",
    "                if any(ex == x for x in ['.temp.clu', '.klg', '.fmask.', '.fet.']):\n",
    "                    try:\n",
    "                        int(os.path.splitext(filename[1:])[-1][1:])\n",
    "                        return True\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "                elif '.initialclusters.' in ex:\n",
    "                    filename = filename.split('.')\n",
    "                    try:\n",
    "                        int(filename[2])\n",
    "                        int(filename[4])\n",
    "                        return True\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "    return False\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_temp = True\n",
    "\n",
    "if delete_temp:\n",
    "    \n",
    "    for file in set_files:\n",
    "        set_path = os.path.splitext(set_files[0])[0]\n",
    "        temp_files = get_temp_files(set_path, append=cut_append)\n",
    "        for _f in temp_files:\n",
    "            os.remove(_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
